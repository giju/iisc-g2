{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import pandas  as pd  \n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import os; \n",
    "  \n",
    "from health.utils import list_files,slugify, DTYPE_DICT, STR_COLS\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "TARGET='Depression'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleans up the columns from raw data to generate processed data\n",
    "Iterate through all folders in the raw folder and generates corresponding cleaned files in the\n",
    "\n",
    "Actions done\n",
    "1. Cleans up CGPA to buckets\n",
    "2. Cleans up Sleep Duration\n",
    "3. Cleans up values for City, Degree,Dietary Habits, Profession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cleanup_CGPA(val):\n",
    "    # if isinstance(float(val),float):\n",
    "    #     return math.floor(float(val)*10)/10\n",
    "    num_val = float(val)\n",
    "    if math.isnan(num_val) or val == \"\":\n",
    "        return -1\n",
    "    return math.floor(float(num_val) * 10) / 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleans up random sleep values to a number and default to 6 hours of sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "two_digit_pattern = r\"(\\d+){1}\\s*[^\\d]{1}+(\\d+)\"\n",
    "single_number_pattern = r\".*([\\d]{2})\"\n",
    "\n",
    "def cleanup_sleep(sleep):\n",
    "    if sleep == \"More than 8 hours\":\n",
    "        return 8\n",
    "    elif sleep == \"Less than 5 hours\":\n",
    "        return 4.5\n",
    "    elif sleep == \"Moderate\":\n",
    "        return 6\n",
    "    elif re.match(two_digit_pattern, sleep):\n",
    "        matches = re.findall(two_digit_pattern, sleep)\n",
    "        num1, num2 = matches[0]\n",
    "        # return sleep\n",
    "        total = (int(num1) + int(num2)) / 2\n",
    "        if total < 10:\n",
    "            return total\n",
    "        return 6\n",
    "\n",
    "    else:\n",
    "        # print('Sleep non confirmant value', sleep)\n",
    "        # raise Exception(f'Invalid value for sleep duration {sleep}')\n",
    "        return 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleanup with an allowed list of values to remove error data ,everything not found is bucketed to other or a default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cleanup_with_lables(name, allowed=[]):\n",
    "    if name == '':\n",
    "        return '';\n",
    "    if name in allowed:\n",
    "        return name \n",
    "    return allowed[-1]\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check unique labels on each cols\n",
    "raw_files = list_files(\"../data/raw\")\n",
    "\n",
    "df_list = []\n",
    "for f in raw_files:\n",
    "    if not (\".csv\" in f):\n",
    "        continue\n",
    "\n",
    "    d = pd.read_csv(\n",
    "        f, dtype= DTYPE_DICT\n",
    "    )\n",
    "    df_list.append(d)\n",
    "            # Combine the list of dataframes\n",
    "df =  pd.concat(df_list)\n",
    "cols = df.columns.to_list() \n",
    "cols.remove(\"id\")\n",
    "cols.remove(\"Name\")\n",
    "\n",
    "\n",
    "for col in cols:\n",
    "    df2 = df[col].value_counts().to_frame('Count').reset_index()\n",
    "    # print(f\"Generated {col}\")\n",
    "    max_val = df2['Count'].max()\n",
    "    row_len = len (df2)\n",
    "    # print(col , row_len,max_val)\n",
    "    if (col in STR_COLS) and len(df2) > 5 : \n",
    "        print(f'Cleaning up {col} - {row_len} {df2.columns.to_list()} - max {max_val}' )\n",
    "        df3 = df2[df2['Count'] > max_val/100 ] \n",
    "        df3 = df3.rename(columns={col: 'name'})\n",
    "        df3.to_csv(f'../reports/raw/labels-{slugify(col)}.csv',index=False)\n",
    "\n",
    "    df2.to_csv(f'../reports/raw/vals_{slugify(col)}.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(val, col, labels=[]):\n",
    "\n",
    "    if col == \"CGPA\":\n",
    "        return cleanup_CGPA(val)\n",
    "    elif col == \"Sleep Duration\":\n",
    "        return cleanup_sleep(val)\n",
    "    # elif col == ''\n",
    "    elif len(labels) > 0:\n",
    "        return cleanup_with_lables(val, labels)\n",
    "    else:\n",
    "        return val\n",
    "\n",
    " \n",
    "\n",
    "def clean_data(input, column_names):\n",
    "    result = pd.DataFrame()\n",
    "    result[\"id\"] = input[\"id\"]\n",
    "    for col in column_names:\n",
    "        try:\n",
    "            sl = slugify(col)\n",
    "            labels = []\n",
    "            label_file = f\"../health/labels/{sl}.csv\"\n",
    "            if os.path.isfile(label_file):\n",
    "                df = pd.read_csv(filepath_or_buffer=label_file) \n",
    "                labels = df['name'].unique()\n",
    "                print(f\"reading {label_file} : \",len(labels))\n",
    "            result[col] = input[col].apply(lambda x: cleanup(x, col, labels=labels))\n",
    "            # break\n",
    "        except Exception as err:\n",
    "            print(\"error occured\", err)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def clean_all_files():\n",
    "    raw_files = list_files(\"../data/raw\")\n",
    "     \n",
    "    for f in raw_files:\n",
    "        if not (\".csv\" in f):\n",
    "            continue\n",
    "\n",
    "        target = f.replace(\"/raw/\", \"/processed/v1/\")\n",
    "        if (os.path.isfile(target)):\n",
    "            print(f\"File '{target}' already exists\")\n",
    "            continue;\n",
    "        print(f\"processing '{f}' \")\n",
    "        df = pd.read_csv(\n",
    "            f, dtype= DTYPE_DICT\n",
    "        )\n",
    "        column_names = df.keys().to_list()\n",
    "        column_names.remove(\"id\")\n",
    "        column_names.remove(\"Name\")\n",
    "        # result = clean_data(df, column_names) \n",
    "\n",
    "        result = clean_data(df, column_names) \n",
    "        result.to_csv(target,index=False)\n",
    "        print(f\"Completed '{f}' \") \n",
    "\n",
    "clean_all_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
